{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import skimage\n",
    "import utils as imgTrans\n",
    "import fileIO as importFile\n",
    "import matplotlib.pyplot as plt\n",
    "import mlUtils as mL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneHotEncoding(speciesDic):\n",
    "    curList = []\n",
    "    for key in speciesDic:\n",
    "        curList.append(speciesDic[key])\n",
    "    speciesSet = set(curList)\n",
    "    \n",
    "    newDic = {}\n",
    "    cnt = 0\n",
    "    for key in speciesSet:\n",
    "        newDic[key] = cnt\n",
    "        cnt = cnt + 1\n",
    "    return(cnt,newDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allFiles = importFile.readFileToDic()\n",
    "numLabel,oneHotDic = oneHotEncoding(allFiles)\n",
    "\n",
    "numLayers = 10\n",
    "numRows = 32\n",
    "numCols = 32\n",
    "\n",
    "curPath = '../../data/oryzeae/'\n",
    "\n",
    "tX = np.empty((numLayers*numCols*numRows))\n",
    "tY = np.empty((1,numLabel))\n",
    "vX = np.empty((numLayers*numCols*numRows))\n",
    "vY = np.empty((1,numLabel))\n",
    "testX = np.empty((numLayers*numCols*numRows))\n",
    "testY = np.empty((1,numLabel))\n",
    "\n",
    "for file in os.listdir(curPath):\n",
    "    tiffFile = curPath+file\n",
    "    species = allFiles[file]\n",
    "    \n",
    "    im = skimage.io.imread(tiffFile)\n",
    "    im2 = skimage.transform.resize(im,(numLayers,numRows,numCols),mode='reflect')\n",
    "    \n",
    "    tmp = np.ndarray.flatten(im2)\n",
    "    tX = np.vstack((tX,tmp))\n",
    "    \n",
    "    tmp = np.zeros((1,numLabel))\n",
    "    curLabel = oneHotDic[species]\n",
    "    tmp[0][curLabel] = 1\n",
    "    tY = np.vstack((tY,tmp))\n",
    "    \n",
    "    allImg = imgTrans.manyRandImg(im2,20)\n",
    "    for i in allImg:\n",
    "        randNum = np.random.rand((1))\n",
    "        tmp = np.ndarray.flatten(i)\n",
    "        \n",
    "        if randNum < .8:\n",
    "            tX = np.vstack((tX,tmp))\n",
    "            \n",
    "            tmp = np.zeros((1,numLabel))\n",
    "            curLabel = oneHotDic[species]\n",
    "            tmp[0][curLabel] = 1\n",
    "            tY = np.vstack((tY,tmp))\n",
    "        elif randNum < .9:\n",
    "            vX = np.vstack((vX,tmp))\n",
    "            \n",
    "            tmp = np.zeros((1,numLabel))\n",
    "            curLabel = oneHotDic[species]\n",
    "            tmp[0][curLabel] = 1\n",
    "            vY = np.vstack((vY,tmp))\n",
    "        else:\n",
    "            testX = np.vstack((testX,tmp))\n",
    "            \n",
    "            tmp = np.zeros((1,numLabel))\n",
    "            curLabel = oneHotDic[species]\n",
    "            tmp[0][curLabel] = 1\n",
    "            testY = np.vstack((testY,tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tX = np.delete(tX, (0), axis=0)\n",
    "tY = np.delete(tY, (0), axis=0)\n",
    "vX = np.delete(vX, (0), axis=0)\n",
    "vY = np.delete(vY, (0), axis=0)\n",
    "testX = np.delete(testX, (0), axis=0)\n",
    "testY = np.delete(testY, (0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linReg = mL.linear()\n",
    "wHat = linReg.train(tX,tY,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.999038461538\n",
      "validation: 0.779661016949\n",
      "test: 0.756097560976\n"
     ]
    }
   ],
   "source": [
    "Y_hat = linReg.predict(wHat, tX)\n",
    "print(\"train: \"+str(mL.accuracy(tY, Y_hat)))\n",
    "\n",
    "Y_hat = linReg.predict(wHat, vX)\n",
    "print(\"validation: \"+str(mL.accuracy(vY, Y_hat)))\n",
    "\n",
    "Y_hat = linReg.predict(wHat, testX)\n",
    "print(\"test: \"+str(mL.accuracy(testY, Y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "\n",
    "This will be one versus all, so you need to set Y vectors -1 if the sample vector is not the class you're\n",
    "training on, and 1 if it's the class you're training on. Then we train several of these models for\n",
    "each species, and then take the maximum likelihood across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step_size = 0.1\n",
    "lam = 0.1\n",
    "eps = 0.001\n",
    "maxiter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = reg_gradient_desc(X_train_bin, Y_train_bin, X_test_bin, Y_test_bin, step_size, lam, eps, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = output[0] #weights\n",
    "b = output[1] #offsets\n",
    "likelihoods = output[2] #series of likelihoods per gradient descent step\n",
    "test_likelihoods = output[3] #series of test data likelihoods per gradient descent steps\n",
    "errs = 1.0 - np.array(output[4]) #series of errors\n",
    "test_errs = 1.0 - np.array(output[5]) #series of test errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#likelihoods\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iters = len(likelihoods)\n",
    "\n",
    "plt.plot(range(iters), likelihoods, label=\"Train likelihood\")\n",
    "plt.plot(range(iters), test_likelihoods, label=\"Test likelihood\")\n",
    "plt.xlabel(\"Iteration number\")\n",
    "plt.ylabel(\"log likelihood\")\n",
    "plt.title(\"$\\lambda$: \" + str(lam))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#accuracies\n",
    "iters = len(errs)\n",
    "\n",
    "plt.plot(range(iters), errs, label=\"Train error\")\n",
    "plt.plot(range(iters), test_errs, label=\"Test error\")\n",
    "plt.xlabel(\"Iteration number\")\n",
    "plt.ylabel(\"Misclassification error\")\n",
    "plt.title(\"$\\lambda$: \" + str(lam))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step_size = 0.01\n",
    "lam = 0.1\n",
    "eps = 0.001\n",
    "maxiter = 100\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = stoch_reg_gradient_desc(X_train_bin, Y_train_bin, X_test_bin, Y_test_bin, step_size, lam, eps, maxiter, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = output[0]\n",
    "b = output[1]\n",
    "likelihoods = output[2]\n",
    "test_likelihoods = output[3]\n",
    "errs = 1.0 - np.array(output[4])\n",
    "test_errs = 1.0 - np.array(output[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
